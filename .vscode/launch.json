{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        // {
        //     "name": "run_evaluate_task_result",
        //     "cwd": "/workspace/SparseCache/accuracy/lm_eval",
        //     "type": "debugpy",
        //     "request": "launch",
        //     "program": "/workspace/SparseCache/accuracy/lm_eval/evaluate_task_result.py",
        //     "console": "integratedTerminal",
        //     "args": [
        //         "--result-file",
        //         // "results/rte-5-qwen2-7B-cache-0.2.jsonl",
        //         "--task-name",
        //         "rte",
        //         "--num-fewshot",
        //         "5",
        //         "--model-type",
        //         "qwen2",
        //     ]
        // },
        // {
        //     "name": "run_lm_eval_harness",
        //     "cwd": "/workspace/SparseCache/accuracy/lm_eval",
        //     "type": "debugpy",
        //     "request": "launch",
        //     "program": "/workspace/SparseCache/accuracy/lm_eval/run_lm_eval_harness.py",
        //     "console": "integratedTerminal",
        //     "args": [
        //         "--model-type",
        //         // "qwen2",
        //         // "qwen3",
        //         // "opt",
        //         "llama",
        //         "--model-name",
        //         // "/share/models/Qwen2-7B",
        //         // "/share/models/Qwen3-8B",
        //         // "/share/models/Qwen3-4B",
        //         // "/share/models/opt-6.7b/",
        //         // "/root/autodl-tmp/opt-model/opt-6.7b",
        //         // "/share/models/opt-6.7b",
        //         "/share/models/Llama-3-8B-Instruct-262k",
        //         // "/share/models/Meta-Llama-3.1-8B",
        //         // "/share/models/Llama-3.2-3B",
        //         // "--enable_heavy_hitter_masker",
        //         // "--heavy_budget_ratio",
        //         // "0.4",
        //         // "--recent_budget_ratio",
        //         // "0.0",
        //         // "--cache_mode",
        //         // "incremental",
        //         // "--ours",
        //         // "--partial_weight_ratio", "0.2",
        //         // "--partial_weight_path", 
        //         // "/workspace/SparseCache/accuracy/setup/weights/Meta-Llama-3.1-8B_0.2_backup",
        //         // "/root/autodl-tmp/weights/opt-6.7b_0.2",
        //         // "--skewing_matrix_path", 
        //         // "/workspace/SparseCache/accuracy/setup/skewing_matrix/Meta-Llama-3.1-8B.pt",
        //         // "--alpha", "2",
        //         // "--budget", "0.2",
        //         // "--capacity", "0.75",
        //         // "--quest",
        //         "--input-path",
        //         "results/piqa-5.jsonl",
        //         "--output-path",
        //         // "results/rte-5-opt-6.7b-decode-cache-0.1-test.jsonl"
        //         "results/piqa-5-llama-3-8b-inst-262k-vanilla.jsonl",
        //         // "--output-path", "results/rte-5-Llama-3.2-3B-quest-recent-0.1-test.jsonl"
        //         // "--report-path",
        //         // "results/stats_rte-5-opt-6.7b-fast-cache-0.4-incremental.json"
        //     ],
        //     "env": {
        //         "CUDA_LAUNCH_BLOCKING": "1"
        //     }
        // },
        {
            "name": "longbench_pred",
            "cwd": "/root/sparse-load/SparseCache/accuracy/benchmark",
            "type": "debugpy",
            "request": "launch",
            "program": "/root/sparse-load/SparseCache/accuracy/benchmark/longbench_pred.py",
            "console": "integratedTerminal",
            "args": [
                "--model-type",
                // "llama",
                "qwen3",
                "--model",
                // "llama-2-7b-inst-32k",
                // "llama-3-8b-inst-262k",
                "Qwen3-8B",
                "--name",
                // "infinigen-1e9-1-1-test",
                "kvswap-headwise-1000token",
                "--datasets",
                "hotpotqa", "narrativeqa", "multifieldqa_en", "musique", "dureader", "gov_report", "samsum", "passage_retrieval_en", "lcc", "qmsum",
                // "hotpotqa narrativeqa qasper gov_report triviaqa passage_retrieval_en passage_retrieval_zh",
                // "--infinigen",
                // "--partial_weight_ratio", "0.2",
                // "--partial_weight_path", 
                // // "/root/sparse-load/SparseCache/accuracy/setup/weights/Llama-2-7B-32K-Instruct_0.2",
                // "/root/sparse-load/SparseCache/accuracy/setup/weights/Qwen3-8B_0.2",
                // "--skewing_matrix_path", 
                // // "/root/sparse-load/SparseCache/accuracy/setup/skewing_matrix/Llama-2-7B-32K-Instruct.pt",
                // "/root/sparse-load/SparseCache/accuracy/setup/skewing_matrix/Qwen3-8B.pt",
                // "--alpha", "2",
                // "--budget", "0.2",
                // "--capacity", "1",
                "--kvswap",
                "--kvswap-group-size", "4",
                "--kvswap-topk", "250",
                // "--quest",
                // "--arkvale",
                // "--page-size",
                // "32",
                // "--page-budgets",
                // "128", //(4096 / 32)
                // "--n-max-bytes",
                // "21474836480", //(20 * (1 << 30))
                // "--n-max-cpu-bytes",
                // "5242880000", //(50 * (1 << 30))
                // "--page-topks",
                // "32",
            ],
            "env": {
                "CUDA_LAUNCH_BLOCKING": "1",
                "LD_LIBRARY_PATH": "/root/miniconda3/envs/arkvale/lib:${env:LD_LIBRARY_PATH}",
                "PATH": "/root/miniconda3/envs/arkvale/bin:${env:PATH}"
            }
        }
    ]
}