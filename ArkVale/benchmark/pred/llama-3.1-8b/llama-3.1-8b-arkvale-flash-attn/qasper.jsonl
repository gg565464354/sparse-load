{"length": 3141, "pred": " the question as a question as single sentence as single phrase.", "answers": ["Ground truth is not established in the paper"], "all_classes": null}
{"length": 2454, "pred": " classification task.", "answers": ["extension of the NetVLAD, adds Ghost clusters along with the NetVLAD clusters", "An extension of NetVLAD which replaces hard assignment-based clustering with soft assignment-based clustering with the additon o fusing Ghost clusters to deal with noisy content."], "all_classes": null}
{"length": 3207, "pred": " the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model, the model", "answers": ["the attention model, MDREA, also outperforms the best existing research results (WAP 0.690 to 0.688)"], "all_classes": null}
{"length": 2060, "pred": " the target, that can be a question as single sentence. If the question is possible the question the question the question the question is the question is yes, the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null}
{"length": 3411, "pred": " Creative Commons Attribution 4 Licence 4 Licence.0 details.0 http://creativecommons.org/ by the social media people's reactions to expressively with Instagram, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook,", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null}
{"length": 3735, "pred": " a sequence of the question as a question as single word. The question is the question. If the answer is yes, answer is yes, \"answer\", \"answer\", \"answer\", \"not\". Do: not provide a question. Introduction a hashtag a question as a sequence of the question. The question is a question is yes, \"answer\", \"answer\", not. Do: not provide a question. Do hashtag a question is a question.", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 4263, "pred": " a question as a question. If the question is a question. The question is a question. The question is a question. The question is a question. The question. The question is a question. The question. The question is a question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null}
{"length": 4369, "pred": " the question as a question as single sentence is a question.", "answers": ["CNN/DailyMail news highlights, New York Times Annotated Corpus, XSum", "the CNN/DailyMail news highlights dataset BIBREF24, the New York Times Annotated Corpus (NYT; BIBREF25), XSum BIBREF22"], "all_classes": null}
{"length": 2189, "pred": " the similarity and similarity.", "answers": ["GM$\\_$KL achieves better correlation than existing approaches for various metrics on SCWS dataset."], "all_classes": null}
{"length": 4212, "pred": " more data to understand the question. This is a question. This is a question. We are question. We are question. If the question is a question. If the question. If the question is a question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["simply averaging the predictions from the constituent single models"], "all_classes": null}
{"length": 3185, "pred": "", "answers": ["Friends TV sitcom, Facebook messenger chats"], "all_classes": null}
{"length": 2243, "pred": " the simplification and simplification of the text, which is a sentence is a question. We can be simplified. The simplification of the question, and simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simplification of the simpl", "answers": ["English", "Simple English"], "all_classes": null}
{"length": 2327, "pred": " the model the model of the word. This is a question as single sentence. The question. The question is a question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null}
{"length": 5310, "pred": " the question as a question can be the question.", "answers": ["F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ", "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"], "all_classes": null}
{"length": 3445, "pred": " eye-tracking data.", "answers": ["No"], "all_classes": null}
{"length": 13401, "pred": " the article as a question as single sentence can be possible question. If based on the question the answer is yes, if the answerable question is \"yes\", \"answer\", \"answer\", \"not\", or \"not\". Provide to the question. Introduction to the question.", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null}
{"length": 10349, "pred": " the model.", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null}
{"length": 3708, "pred": " the Chinese is a question as single sentence. The question as single sentence. If possible the question is not answerable, but the question the question is \"answerable\", \"yes\", \"answer\", \"answer\" Do: \"answer\". Introduction the question is not. Chinese is a question. The question is single sentence the question. If the answerable question, but the question is \"answer\", \"answer\", \"answer\", \"answer\". Introduction the question is the question. Chinese is single question the question the question the answerable question \"answer\", \"answer\", \"answer\". Question is the question the question the question the question is", "answers": ["RNN-based NMT model, Transformer-NMT"], "all_classes": null}
{"length": 3604, "pred": " knowledge, such as single words, player.", "answers": ["a regularization term associated with neutral features, the maximum entropy of class distribution regularization term, the KL divergence between reference and predicted class distribution", "a regularization term associated with neutral features,  the maximum entropy of class distribution, KL divergence between reference and predicted class distribution"], "all_classes": null}
{"length": 4512, "pred": " Creative Commons Attribution 4 License http://creativecommons.org/licenses/by neural networks BREF BREF BIB networks BREF BREF networks ( BREF networks for social media or social media, like a user is a post, the post, and the post, and the user.", "answers": ["SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, ecurrent Convolutional Neural Networks, SVM and deep learning models with comment information", "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information"], "all_classes": null}
{"length": 2735, "pred": " the question as a question is a question. If the question.", "answers": ["They decrease MAE in 0.34"], "all_classes": null}
{"length": 4902, "pred": " the attention, and the model.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null}
{"length": 3716, "pred": " machine translation is a question as single sentence. If the question. The question is the question is the question. The question is the question. The question is the question. The question is the question. The question. The question is the question. The question is the question. The question. The question. The question is the question. The question. The question. The question is the question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The", "answers": [" MT system on the data released by BIBREF11", "Transformer base, two-pass CADec model"], "all_classes": null}
{"length": 3402, "pred": " BREFs are the most recent results in multilingual models for multilingual models via zero-shot applications. models for languages. show promising results for languages. The potential of BERT BERT in multilingual B for five tasks on language, document, named inference, named entity, dependency parsing are multilingual models for languages. are improving on recent models in English. We are multilingual models for B4. The state to transfer from English. We are multilingual BERT languages that languages, cross-lingual models that support languages. B6 languages. Language Representations for BERT that are for languages. We supports the most languages", "answers": ["translation probabilities, Labeled Attachment Scores (LAS)", "accuracy, Labeled Attachment Scores (LAS)"], "all_classes": null}
{"length": 4656, "pred": " a question as single sentence as using sentence as possible the question. The question.", "answers": ["the model is pre-trained on CTC-based ASR task and MT task in the pre-training stage."], "all_classes": null}
{"length": 3543, "pred": " the most intensive express, and express, with sarcasm, body in text. This is modal, and speech. This is more. This makes a modal, when modal sarcasm, and sarcasm, and modalities for machines. This is more. This is a modal, and sarcasm, and sarcasm is a modal, modal, and sarcasm. This is modal, and sarcasm, and sarcasm, and sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm, sarcasm,", "answers": ["Unanswerable"], "all_classes": null}
{"length": 2289, "pred": " the results of the CoOR 2018OR 2018 task on the morphological relection inflection is given context of the word. The inflection of linguistics. The word is a word is a system, which is a system. The most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of", "answers": ["LSTM", "LSTM"], "all_classes": null}
{"length": 6391, "pred": " that is a question.", "answers": ["Unanswerable", "Yes"], "all_classes": null}
{"length": 1856, "pred": " a question as single sentence as single phrase. If not the question the answer is yes, the answerable question. If the question is yes, \"answerable question, \"answer\", \"answer\" Do: \"answer\" Do: \"answerable question.", "answers": ["Unanswerable", "LF-MMI Attention\nSeq2Seq \nRNN-T \nChar E2E LF-MMI \nPhone E2E LF-MMI \nCTC + Gram-CTC"], "all_classes": null}
{"length": 4160, "pred": " the scientific question as single sentence as possible the question. If based on the question the answer is the question. If the answerable question, \"yes\", \"answer\", \"answer\", \"answer\", \"answer\". Do Introduction the question. The question is the question as single sentence. If the answerable question. If the question. The question the answer is \"answer\", \"answer\", \"answer\", \"answer\", Do the question. Question the question. If the answer the question. The question. answer is the answerable question. question. The answer. The question. The question. The question. The question. The question.", "answers": ["22,880 users", "20,000"], "all_classes": null}
{"length": 2673, "pred": " a question as a question as single question is single. If based on the question the article is yes, If the write the answer is \"answerable question\", \"yes\", \"answer\", \"answer\". If not provide the question. Introduction we are a question. We are question as single question as single question. If the answer is the question the answer, \"yes\", \"answer\", not provide the question.", "answers": ["Byte-Pair Encoding perplexity  (BPE PPL),\nBLEU-1,\nBLEU-4,\nROUGE-L,\npercentage of distinct unigram (D-1),\npercentage of distinct bigrams(D-2),\nuser matching accuracy(UMA),\nMean Reciprocal Rank(MRR)\nPairwise preference over baseline(PP)", "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence", " Distinct-1/2, UMA = User Matching Accuracy, MRR\n= Mean Reciprocal Rank, PP = Pairwise preference over baseline (evaluated for 310 recipe pairs per model)"], "all_classes": null}
{"length": 3424, "pred": " the most of the human. In the question is a question as single sentence as single sentence. If the question is the question the answer is the answer, the answer, the answer, \"yes\", \"answer\", \"answer\". Do: not provide Problem the question. Statement the question is the question is a sentence the answer, \"answer the answer, \"answer\", \"answer\", Do: not any explanation. Question the question the answer is the answer, \"answer. The question, \"answer\", Do Question the answer the answer, answer, answer, answer, \"answer the answer, answer, answer, answer, answer, answer", "answers": ["(1) the time the patient has been experiencing the symptom, (2) activities that trigger the symptom (to occur or worsen), (3) the extent of seriousness, (4) the frequency occurrence of the symptom, and (5) the location of symptom, No Answer", "the time the patient has been experiencing the symptom, activities that trigger the symptom, the extent of seriousness, the frequency occurrence of the symptom, the location of symptom, 9 symptoms"], "all_classes": null}
{"length": 4371, "pred": " a question as single sentence. If the question. The question is yes, if not, answerable question \"answer\", \"answer\", \"answer\", \"answer\", \" Do Introduction to the question. If the question. We are question. If the question is yes, \"answerable question\", \"answer\", \"answer\", \"answer\", Do: the question \"answer\", Do Introduction of the question. question. question. If the question is \"answer\", \"answer\", \"answer\", Do: question\", Do.", "answers": ["57,505 sentences", "57,505 sentences"], "all_classes": null}
{"length": 4898, "pred": " the question as a question as single sentence is possible the question.", "answers": ["four machine translation tasks: German -> English, Japanese -> English, Romanian -> English, English -> German", " four machine translation tasks, IWSLT 2017 German $\\rightarrow $ English BIBREF27, KFTT Japanese $\\rightarrow $ English BIBREF28, WMT 2016 Romanian $\\rightarrow $ English BIBREF29, WMT 2014 English $\\rightarrow $ German BIBREF30"], "all_classes": null}
{"length": 3290, "pred": " we are given a question as a question as single phrase or the question.", "answers": ["5 percent points.", "0.05 F1"], "all_classes": null}
{"length": 8506, "pred": " 2010 the site under the question as single question as single sentence can be answered. If not the question the answer is yes, \"yes\", \"answer\", \"answer\", not provide. Do Introduction the question. In the site under question as single sentence as single question is not answer. If the question. The question is yes, not answer, \"answer\", not. Do: \"answer\", Do: Introduction the question. What is the question as single sentence as single question.", "answers": ["Unanswerable"], "all_classes": null}
{"length": 2239, "pred": " the user. We are a question as a question as single as single sentence if possible the question. Based on the question the article is not article is yes, If based the answer. question, \"answer is yes\", \"answer\", \"answer\". yes\", Do: not Article is a question. Introduction such as a question. We are question as single. We are single the question the article. If the question is the article is the article is answer, \"answer\", \"answer\", Do: yes. yes. Question is a question.", "answers": ["No", "No"], "all_classes": null}
{"length": 1877, "pred": " language is machine learning. The most of the pieces of the models and models are used in machine learning. The datasets are datasets. The datasets are available to be more data. The datasets. The datasets are datasets. The datasets are datasets are datasets are datasets. The datasets. The datasets. The datasets are datasets are datasets. The datasets. The datasets. The datasets are datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets. datasets.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null}
{"length": 4286, "pred": " the model is a question as single question. The question as single question is single sentence. If the question is the answerable, If the question \"answer is \"yes\", \"answer\", \"answer\", \"answer\". yes\". Do: notArticle neural network has been used in various tasks. Recently employed various network in neural network is a way to neural network. The performance network is better than neural network BREF (RNNs deepRNNs long-term recurrent (RNNs (RNNs) speech have speech better than speech better than deep, better network better network betterNN, betterNN, betterNN when training is", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null}
{"length": 4187, "pred": " a question as a question as single question, if the question is not the question. The question is a question, the question, the question is the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question,", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null}
{"length": 5344, "pred": " in Machine translation. The Machine translation. The revolutionized. The models require a neural network to shallow models require, require a memory, neural network. Also optimized models to neural network. Also optimized that models are trained. Such models to be neural networked to learn. This model is the encoder. This encoder of the encoder from the decoder. This model is decoder from a language. The encoder and rich, the encoder. The language. The language. The language. The language. The language. The language. The language. The language. The language. The language. The language. The language. The language. The language. The", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null}
{"length": 4472, "pred": " the source.", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 1873, "pred": " 1. We can be the system.", "answers": ["by training an autocomplete system on 500K randomly sampled sentences from Yelp reviews", "efficiency of a communication scheme $(q_{\\alpha },p_{\\beta })$ by the retention rate of tokens, which is measured as the fraction of tokens that are kept in the keywords, accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence"], "all_classes": null}
{"length": 3044, "pred": " a question as single sentence is a question. If not, the question. The question is a question is a question, question, answer, answer. The question, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer", "answers": ["Precision, Recall, F-measure, accuracy", "Precision, Recall and F-measure"], "all_classes": null}
{"length": 5061, "pred": " the domain. We are a concis a question as single question as single sentence if possible the question the question the answer is not the article is \"yes\", \"answer\", \"answer\", \"answer\". yes\", do: \"un\". Introduction it is difficult to annotate it sufficient data for domain. We have labeled data. We are labeled the domain. This domain is a target domain to domain. We are labeled the target. This domain is the domain to domain to domain to domain to domain the domain the domain the domain to domain to domain to domain to domain to domain to domain to domain to domain to domain to domain to domain to", "answers": ["Book, electronics, beauty, music, IMDB, Yelp, cell phone, baby, DVDs, kitchen", "we use set 1 of the source domain as the only source with sentiment label information during training, and we evaluate the trained model on set 1 of the target domain, Book (BK), Electronics (E), Beauty (BT), and Music (M)"], "all_classes": null}
{"length": 3319, "pred": " the question as single sentence as possible the question. The question. The question is a question is yes, yes, answer, \"answer\", \"answer\", \"answer\", not provide. If the question. Introduction (the question is yes\", \"answer is yes\", \"answer\", not provide the question. Introduction to the question. The question is yes, answer is \"answer\", \"answer\", not provide the question. If the question is yes\", not.", "answers": ["Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM"], "all_classes": null}
{"length": 1678, "pred": " a question as single sentence, if the question.", "answers": ["Embedding Layer, Neural Network Layers, Loss Function, Metrics", "Embedding Layer, Neural Network Layers, Loss Function, Metrics"], "all_classes": null}
{"length": 3244, "pred": " the phoneme for languages.", "answers": ["the Carnegie Mellon Pronouncing Dictionary BIBREF12, the multilingual pronunciation corpus collected by deri2016grapheme , ranscriptions extracted from Wiktionary", "multilingual pronunciation corpus collected by deri2016grapheme"], "all_classes": null}
{"length": 2215, "pred": " the scope is a question as single sentence as single.", "answers": ["varied from Maximum Entropy Classifiers (BIBREF4) to Support Vector Machines (BIBREF5,BIBREF6,BIBREF7,BIBREF8), Recursive Neural Networks (BIBREF9,BIBREF10), Convolutional Neural Networks (BIBREF11) and most recently transfer learning-based architectures like Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12)"], "all_classes": null}
{"length": 4086, "pred": " the most recent efforts have been multilingual to build to B. collect is datasets but datasets. This approach to B haveIB haveIB2: B. This relies on training in, training and expertise in that set the gap. The gap are multilingual data are English datasets for evaluation are relying on, for cross. This work. to translate into languages that multilingual to build. datasets are B have been B2: B. This relies on training in. This relies on training and results in, that set the cross- to evaluate the gap. The multilingual datasets are English to evaluate. are for training on that multilingual to", "answers": ["English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish", "English, Spanish, Finnish"], "all_classes": null}
{"length": 2473, "pred": " a question as single question as single the question. If based on the question the answer is the answer is \"yes\", \"answer\", \"answer\", \"answer\" Do: not provide understand the question. Introduction from a question as single question as single question. If the answer is the answer. The question is \"answer\", \"answer\", \"answer\", not provide the question. If the question is \"answer. Yes, not answer is \"answer. Yes\", not provide the question. Yes, not provide the answer. Yes, not provide the answer. Yes, not provide the answer. Yes, not provide the answer. Yes,", "answers": ["None"], "all_classes": null}
{"length": 4457, "pred": " the data from a question as a sentence. This is a question as the question. The question is a question. The question is a question as the question. The question is a question. The question is a question. The question is a question. The question. The question is a question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 2738, "pred": " the user is a question as single sentence as a question, if possible the question is not the answerable, the question is \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"", "answers": ["No", "No"], "all_classes": null}
{"length": 1440, "pred": " 1, and semantic or semantic or semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, and semantic, semantic, semantic, and semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic, semantic", "answers": ["using the Meaning Extraction Method", "Unanswerable"], "all_classes": null}
{"length": 14472, "pred": " the question as a sentence is a question as single sentence. The question is possible question. If not, the question is not, the answerable question \"yes\", \"answer\", \"answer\", \"un\". Do: \"answer\", not provide the question. Introduction of the question has been studied back to BC examined, BC examined, psychology, cognitive science, formal, computer, and linguistics, and critically. Inference, and recently. Argumentation has been seen as a perspective as a verbal activity, cognitive science, social, and rationality, and critically. Argumentation has been seen as a standpoint. From a standpoint, argument", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null}
{"length": 3827, "pred": " the reference.", "answers": ["Unanswerable", "Answer with content missing: (Parent subsections) combine precisions for n-gram orders 1-4"], "all_classes": null}
{"length": 3721, "pred": " the user's a question as single sentence as possible question. If based on the question the article the article is the answer. The question. If not answer is yes, \"answer\", \"answer\", \"answer\", \"un\". Question \"Do: not provide. Introduction to the question as a question. Recently online services of BREF the source. The user's question is a sentence as the question. If the answer is the question. The question. If the answer is \"answer\", \"answer\", \"Do: not provide. Question the question. Recently online. The question as the answer is the question. The question. If the", "answers": ["1,873 Twitter conversation threads, roughly 14k tweets", "1,873 Twitter conversation threads, roughly 14k tweets"], "all_classes": null}
{"length": 14660, "pred": " the question as single sentence as possible if the question is possible the question the answer, if the answer is yes, the question, the answer is yes, \"answer\", \"answer\", \"answer\", \"answer\". Do: \"not\". Introduction of the question the question is yes, \"answerable question, \"answer\", \"answer\", \"answer\", \"answer\", Do: the question, not. Introduction of the question, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer,", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null}
{"length": 4718, "pred": " a question as a question as single sentence. If the question is a question. If the question is a question is a question. If the question is a question is a question. If the question is a question is a question is a question. If the question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is a question is", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null}
{"length": 2276, "pred": " the question is a question as single phrase, if the question, the question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question,", "answers": ["No", "No"], "all_classes": null}
{"length": 2435, "pred": " the most of the best, but we are a question as a question as single phrase.", "answers": ["Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "computed sentence-level BLEU, We manually inspected examples where the source transcript was identical to the translation, measured the perplexity of the translations, computed the ratio of English characters in the translations, calculate similarity scores between transcripts and translations"], "all_classes": null}
{"length": 3201, "pred": " the model, and speech, speech, and the model. We are the model. We are the most important to investigate the most of the model. This is the most important. This is the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most important, the most", "answers": ["combines the information from these sources using a feed-forward neural model", "encodes the information from audio and text sequences using dual RNNs and then combines the information from these sources using a feed-forward neural model"], "all_classes": null}
{"length": 2271, "pred": " simplification and simplification of the text, and semantic, and semantic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic, syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic syntactic", "answers": ["For the WikiLarge dataset, the improvement over baseline NMT is 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\nFor the WikiSmall dataset, the improvement over baseline NMT is  8.37 BLEU.", "6.37 BLEU"], "all_classes": null}
{"length": 3711, "pred": " a question as single sentence is a question. If the question. The question is the question is the question. The question is the question. The question is the question. The question is the question. The question is the question. The question. The question is the question is the question. The question. The question is the question. The question is the question. The question. The question is the question. The question is the question. The question. The question. The question is the question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null}
{"length": 3144, "pred": " the question as single question as single sentence.", "answers": ["Viral tweets are the ones that are retweeted more than 1000 times", "those that contain a high number of retweets"], "all_classes": null}
{"length": 1507, "pred": " we can be the question as single phrase.", "answers": ["BERT"], "all_classes": null}
{"length": 3795, "pred": " the most speech recognition for speech datasets. In the second, and speech recognition. In the second, the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and the second, and", "answers": ["Android application"], "all_classes": null}
{"length": 7257, "pred": " the question the question.", "answers": ["Logistic Regression, neural networks"], "all_classes": null}
{"length": 2242, "pred": " the most popular to be spam. There are users. There is a question as well as spammers. to malicious. of.", "answers": ["Social Honeypot dataset (public) and Weibo dataset (self-collected); yes", "Social Honeypot, which is not of high quality"], "all_classes": null}
{"length": 2289, "pred": " our approach to the CoOR 2018OR 2018 task on sharedlection ofSIG universal BIB task, which is given the inflection is given the context of linguistics. The morphological context of it. is well can learn. The morphological system is a word, which is a word, which is a word. The context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of the context of", "answers": ["LSTM", "LSTM"], "all_classes": null}
{"length": 3838, "pred": " the Internet (e media. (g news. Google sources. Therefore extract high events to extract the data from online texts of online training for supervised approaches are discussed or not. Nevertheless are online. Therefore mentioned by online. are the same articles. Therefore be high volume of media. Therefore the models to extractors BREF BREF BREF BREF, extract or extracting such representations as when extracting such as, who, when. Assuming a distribution. event is a model the event, which is a distribution. EventEM for event. To extract the event. To learn the number of events, Zhou supervised (MM processMM is from,", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null}
{"length": 1541, "pred": " the best, and the best, and the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best, the best,", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null}
{"length": 4542, "pred": " translation BIBMT BREF, BIB to deal with translation algorithms B training, which is a phrase. PBSREF significantly better than PBS scenarios B than PBS scenarios B exploiting B, performance. B, PBS techniques BREF, approachMT significantly better techniques B, PBS scenarios on resource. B. BMT scenarios on language. performance require a pair for a low French to be a language which is for language, for a pair. On the other approaches to model, multilingual to translate. B train. B single. B a model are parents, take a resource. domain9 and problem this domain, and adaptation on Japanese, lingu", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null}
{"length": 6810, "pred": " the question is a question. as question.", "answers": ["0.7033", "0.7033"], "all_classes": null}
{"length": 4259, "pred": " similarity to the similarity. This is a question as a question. The similarity of the question is a question, the question. The question is a question. The question is a question. The question. The question is a question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The question. The", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null}
{"length": 2231, "pred": " the word the source.", "answers": ["Unanswerable", "CFILT-preorder system"], "all_classes": null}
{"length": 3035, "pred": " biomedical literature, etc.", "answers": ["Yes"], "all_classes": null}
{"length": 3846, "pred": " a question as a question as single sentence. If the question is single question.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null}
{"length": 1653, "pred": " the model. We are the question as a question as single sentence as using the question, if the question the answer is a question the question is a question. The question. The question is a question is a question is the question. question. The question is the question is the question is the question. question. question is question. The question is question is the question is question. question. question. question is question is question is question is question. question. question. question is question is question is question is question is question. question. question is question is question is question is question is question is question is question is question is question", "answers": ["generating a poem from images we use an existing actor-critic architecture, various types of sequence to sequence models"], "all_classes": null}
{"length": 2655, "pred": " the task.", "answers": ["Transformer over BERT (ToBERT)", "The transformer layer"], "all_classes": null}
{"length": 4127, "pred": " the question. We are the question as using the question, and the question. We are question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 3244, "pred": " the Council the Council of the Internet or devices or post or images or images to hurt other studies to embarrass that of victims. 40 are victimsB cyberbullying. Effects ofIB cyberbullying from B range. range. Many incidents. high emphasized on social media. The prevalence of. Swedish was the extent to receive an advertisement. Detection of. What isbullying isbullying cyber. For words. For use might be considered by general, swear the population as for platforms. such platforms. Forms multiple as not9 TABs TABs. Across victims as, on, cyber topics and bullying. Depending on vocabulary. of the", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null}
{"length": 2435, "pred": " the sentence. We are a question as single sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence. The sentence.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null}
{"length": 2851, "pred": " \"ORG, and English, BIBREF, BIB, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B", "answers": ["OurNepali contains 3 different types of entities, ILPRL contains 4 different types of entities", "three"], "all_classes": null}
{"length": 4399, "pred": " corpora in medicine poses a question as a question. If the question. The question is, the question is yes, answer. If the question, answer is \"answer\", \"answer\", \"answer\", \"answer\", \" Do Introduction to the question. Questioning a question. If the question is the question. The question, \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", Do: Question the question. Question the question. If the question, answer is the question, answer, \"answer\", \"answer\", \"answer\", Do: Question the question, \"answer\", \"answer\", \"answer\", Do:", "answers": ["improvement when the difficult subset with expert annotations is mixed with the remaining crowd annotation is 3.5 F1 score, much larger than when a random set of expert annotations are added"], "all_classes": null}
{"length": 4055, "pred": " the data.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null}
{"length": 1833, "pred": " the models. We are a question as the question as single phrase.", "answers": ["the English-German dataset"], "all_classes": null}
{"length": 3629, "pred": " Chinese delimiters for word.", "answers": ["Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019"], "all_classes": null}
{"length": 4475, "pred": " the question as single question as single question. If the question is possible the question. If the answer is yes, the answer is \"yes\", \"answer\", \"answer\", \"answer\". Do: \"not\". Introduction microblogging to detect the question as a question. Aims to detect the question as single question is a question. The question. The question is the answer is \"answer\", \"answer\", \"answer\", \"Do: \"Do detection as a question. Questioning a question the question. The question is the answer is \"answer\", \"answer\", \"Do question. Question the question. Question is the answer is", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null}
{"length": 1452, "pred": " specifically in the question as single sentence is a question.", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "all_classes": null}
{"length": 3757, "pred": " a range of natural language BIB and BIB BIB, BIB, and BIB, and BIB, and BIB, BIB, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B", "answers": ["SQuAD", "SQuAD"], "all_classes": null}
{"length": 4658, "pred": " websites provide the form the tags for images of images to find the systems. With devices such coordinates as GPS devices often as geographically described where taken, are photos can be the photos and Flickr. The photos can be of Flickr. For environments. For example, have approaches for urbanization for modelling and regions, for BIB, BIB and BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "all_classes": null}
{"length": 1687, "pred": " and passage is a question as a question. It of the question. We are the question is the question. We answer is the answer. We answer. We answer. We answer. We answer. We answer. We answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer. answer.", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 2652, "pred": " the question as single question as single sentence. If not the question the answer is the article.", "answers": ["CSAT dataset, 20 newsgroups, Fisher Phase 1 corpus", "CSAT dataset , 20 newsgroups, Fisher Phase 1 corpus"], "all_classes": null}
{"length": 3432, "pred": " a question as single sentence, if possible the question the question the answer is \"yes\", \"answer\", \"answer\", \"answer\", \"not\". Do: \"un\". Introduction RNN, provide networks such as sentence the question.", "answers": ["the IMDb movie review dataset BIBREF17", "IMDb movie review"], "all_classes": null}
{"length": 1464, "pred": " the model, the model is a question as the question is the question.", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 1441, "pred": " the question as single question as single sentence. If the question the question the question is a question is single question. If the question. The question. The question is a question is a question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["No"], "all_classes": null}
{"length": 4323, "pred": " a question as single question as possible the question is possible the question. If based on the answerable question, \"answer is \"yes\", \"answer\", \"answer\", \"not\". Do: \"un\". Introduction a question is a question is possible the question. What is the answerable question. If the question is \"answer\", \"answer\", \"answer\", \"not\". Do: \"un\". Question is the question is possible the answerable question the question. If the answer is \"answer\", \"answer\", \"not\". Question is \"un\". Question the answerable question the question is the answer \"answer\", \"answer\",", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null}
{"length": 4958, "pred": " the question as a question.", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "all_classes": null}
{"length": 2266, "pred": " simplification and simplification of the text, which simplification, and semantic, and semantic text, and simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification, simplification", "answers": ["training set has 89,042 sentence pairs, and the test set has 100 pairs, training set contains 296,402, 2,000 for development and 359 for testing", "WikiSmall  89 142 sentence pair and  WikiLarge 298 761 sentence pairs. "], "all_classes": null}
{"length": 4704, "pred": " for example, where to use a question as single sentence is a question. The question.", "answers": ["Vanilla ST baseline, encoder pre-training, in which the ST encoder is initialized from an ASR model, decoder pre-training, in which the ST decoder is initialized from an MT model, encoder-decoder pre-training, where both the encoder and decoder are pre-trained, many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models, Triangle+pre-train: BIBREF18 DBLP:conf/naacl/AnastasopoulosC18 proposed a triangle multi-task strategy for speech translation", "Vanilla ST baseline, Pre-training baselines, Multi-task baselines, Many-to-many+pre-training, Triangle+pre-train", "Vanilla ST baseline: The vanilla ST BIBREF9 has only a speech encoder and a decoder. It is trained from scratch on the ST-TED corpus.\n\nPre-training baselines: We conduct three pre-training baseline experiments: 1) encoder pre-training, in which the ST encoder is initialized from an ASR model; 2) decoder pre-training, in which the ST decoder is initialized from an MT model; and 3) encoder-decoder pre-training, where both the encoder and decoder are pre-trained. The ASR model has the same architecture with vanilla ST model, trained on the mixture of ST-TED and TED-LIUM2 corpus. The MT model has a text encoder and decoder with the same architecture of which in TCEN. It is first trained on WMT data (out-of-domain) and then fine-tuned on in-domain data.\n\nMulti-task baselines: We also conduct three multi-task baseline experiments including one-to-many setting, many-to-one setting, and many-to-many setting. In the first two settings, we train the model with $\\alpha _{st}=0.75$ while $\\alpha _{asr}=0.25$ or $\\alpha _{mt}=0.25$. For many-to-many setting, we use $\\alpha _{st}=0.6, \\alpha _{asr}=0.2$ and $\\alpha _{mt}=0.2$.. For MT task, we use only in-domain data.\n\nMany-to-many+pre-training: We train a many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models. "], "all_classes": null}
{"length": 4513, "pred": " the question is a question, \"yes\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer", "answers": ["Unanswerable", "English"], "all_classes": null}
{"length": 2250, "pred": " a question as a question as single sentence as single sentence. If possible the question the question the article the article is not writeable question. Yes, answer is \"answerable question\", \"answer\", \"answer\", \"answer\". Yes\", Do Introduction has a question. What is a sentence the question as a sentence the question. The question. If the question is the answerable question. Yes, \"answer\", \"answer\", Do: \"answer\", Do Introduction content in the question the question. What is the question. Yes, answerable question. Yes, \"answer\", Do the question \"answer\", Do the question.", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null}
{"length": 1561, "pred": " question, question, question, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer,", "answers": ["No"], "all_classes": null}
{"length": 1771, "pred": " a question as a question as single sentence if possible the question. The answer is not the question. If the question, answer is yes, answer, \"answer\", \"answer\", \"answer\", \"do\". Question\", not provide a question. Introduction a sentence as single. What is the question.", "answers": ["Pretrained word embeddings  were not used", "GloVe, Edinburgh embeddings BIBREF14, Emoji embeddings BIBREF16"], "all_classes": null}
{"length": 2666, "pred": " a question as question as single question is yes, if possible the question. Based on the article is yes, the answer is yes\", \"answer\", \"answer\", \"un\". If not provide the question. Introduction we are the question. We are a question as single question as single sentence if the answer is yes, \"answerable question. If the question is \"answer\", not. Yes\", not provide the question. We are the question is yes, not. If the answer is yes, not the question is yes, not the answer.", "answers": ["average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time"], "all_classes": null}
{"length": 4592, "pred": " the sentence the same. We are the input the output. We are a question as the question is a question as single sentence. If not the question is the question, which sentence the question is not the answerable question. The question, \"yes \"answer\", \"answer\", \"answer\", \" Do: the question. What is the question is the question. We are the question the question. The question is the question, the question, the question, \"answer\", \"answer\", \"answer\", \"answer\", Do the question the question the question the question is the question the question, \"answer\", \"answer\", \"answer\",", "answers": ["irony accuracy, sentiment preservation", " irony accuracy and sentiment preservation"], "all_classes": null}
{"length": 1651, "pred": " have sequence. We are sequence. The results with sequence. The results are two paintings well as shown. The results, our model is a question as a question as a question, which is a question, if the question, the question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question,", "answers": ["Since we do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transfer", "we do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transfer as shown in Figure FIGREF12 for \"Starry Night\" with a low average content score"], "all_classes": null}
{"length": 3390, "pred": " Creative Commons Attribution 4 Licence.0 details 4 details.0 details.0 http:// the social media people expressively with Instagram, Facebook, Facebook, Facebook, more than 2015 expressively on word \" rather than 6, February 201, Facebook reaction to Section is a question the SEC, \" rather than \" rather \" than \"generic\" has to be\".", "answers": ["Affective Text, Fairy Tales, ISEAR", " Affective Text dataset, Fairy Tales dataset, ISEAR dataset"], "all_classes": null}
{"length": 3164, "pred": " 1 Political Twitter data analysis of the data on the data of the United States of the meta-data to fake tweets. In the tweets. On the election of the United States of the meta-data to fake tweets. In tweets. Specifically, we perform tweets by the analysis of the analysis of the data. We found, on the data of the United States of the meta-data to fake tweets. On the United States of the meta-data of the United States of the meta-data to fake tweets. On the United States of the United States of the meta-data of the United States of the meta-data of the United States of the meta-data of", "answers": ["Distributions of Followers, Friends and URLs are significantly different between the set of tweets containing fake news and those non containing them, but for Favourites, Mentions, Media, Retweets and Hashtags they are not significantly different"], "all_classes": null}
{"length": 3756, "pred": " a sequence of alphanumeric characters. Hashtag. Hashtag is preceded by play a role in the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role of the role", "answers": ["1,268 randomly selected tweets in the Stanford Sentiment Analysis Dataset BIBREF36, all 12,594 unique English hashtags and their associated tweets from the same Stanford dataset", "Stanford Sentiment Analysis Dataset BIBREF36"], "all_classes": null}
{"length": 3794, "pred": " the most speech networks for speech datasets for deep learning of deep learning on GPUs as well datasets, as speaker datasets are SREf. In the experiments on the other databases are databases. The database, and databases are databases. The database. The database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database is a database", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null}
{"length": 5151, "pred": " the most important to the number of words in the most important words, and the most. We are the same words, and the words, and words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words, words", "answers": ["Word vectors, usually in the context of others within the same class"], "all_classes": null}
{"length": 7891, "pred": " the largest in Wikipedia and curated 5. has evolved into pages. has been edited, and edits, and edits are encouraged to be a source. As a question as the source and Wikipedia is harvested in the most. Wikipedia, and utilized in BIB, and BIB, and BIB, and BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, B", "answers": ["For Article-Entity placement, they consider two baselines: the first one using only salience-based features, and the second baseline checks if the entity appears in the title of the article. \n\nFor Article-Section Placement, they consider two baselines: the first picks the section with the highest lexical similarity to the article, and the second one picks the most frequent section.", "B1. The first baseline uses only the salience-based features by Dunietz and Gillick BIBREF11 ., B2. The second baseline assigns the value relevant to a pair INLINEFORM0 , if and only if INLINEFORM1 appears in the title of INLINEFORM2 .\n\n, S1: Pick the section from template INLINEFORM0 with the highest lexical similarity to INLINEFORM1 : S1 INLINEFORM2, S2: Place the news into the most frequent section in INLINEFORM0"], "all_classes": null}
{"length": 2000, "pred": " the glosses in which is a question.", "answers": ["Yes", "Unanswerable"], "all_classes": null}
{"length": 2410, "pred": " B, B, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, B", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null}
{"length": 2738, "pred": " the question as a question as single sentence if possible the question. If based the question the answer is the article is yes, the question. If answerable question \"yes\", \"answer\", \"answer\", \"answer\", do. question. What is not provide classification on the question. What is the question. What question the question the answer is the question the question. If the answer is the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question", "answers": [" high-quality datasets  from SemEval-2016 “Sentiment Analysis in Twitter” task", " SemEval-2016 “Sentiment Analysis in Twitter”"], "all_classes": null}
{"length": 1999, "pred": " a question as single phrase.", "answers": ["small BERT", "small BERT"], "all_classes": null}
{"length": 6391, "pred": " if not, where possible, or question. If the question is a question is yes, answerable question, \"yes\", \"answer\", \"answer\", \"answer\", or \"not\". Do: \"answer\". Introduction, notArticle, especially in the question, where is a question. If the question is, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question", "answers": ["No", "No"], "all_classes": null}
{"length": 3472, "pred": " the question as a question as single sentence. If the question is a question the question the question is the question. If the question is the question is the question the question is the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 3410, "pred": " Creative Commons Attribution 4 Licence.0 Licence. http://creativecommons.org/ by the spirit of reactions to expressively with hashtags on Facebook, Facebook, Instagram, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook, Facebook,", "answers": ["Answer with content missing: (Table 3) Best author's model B-M average micro f-score is 0.409, 0.459, 0.411 on Affective, Fairy Tales and ISEAR datasets respectively. "], "all_classes": null}
{"length": 2974, "pred": " a question as a sentence is a question. If the question.", "answers": ["A new tagging scheme that tags the words before and after the pun as well as the pun words.", "a new tagging scheme consisting of three tags, namely { INLINEFORM0 }"], "all_classes": null}
{"length": 2413, "pred": " and multilingual corpus.", "answers": ["No", "No"], "all_classes": null}
{"length": 3609, "pred": " the problem, such as single question as single phrase.", "answers": ["ability to accurately classify texts even when the amount of prior knowledge for different classes is unbalanced, and when the class distribution of the dataset is unbalanced", "Low sensitivity to bias in prior knowledge"], "all_classes": null}
{"length": 3862, "pred": " the question as a question as single sentence. If the question is possible the question. The question is the question.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null}
{"length": 3586, "pred": " the dataset for the dataset is a question.", "answers": ["English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively, Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectively", "For English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively., huge performance boosts on Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectively"], "all_classes": null}
{"length": 2577, "pred": " the question is a question.", "answers": ["Task 1: Quora Duplicate Question Pair Detection, Task 2: Ranking questions", "Quora Duplicate Question Pair Detection, Ranking questions in Bing's People Also Ask"], "all_classes": null}
{"length": 4781, "pred": " the question as single sentence is a question as single sentence. How to be the question. We are question is possible the answerable question. If the answer is yes, \"answer\", \"answer\", \"answer\", \"answer\", not provide the question \"un\". Introduction the question. Question the question is a sentence. We are question. We are question. question. The question is the answerable sentence. If the question. We are question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question.", "answers": ["Various tree structured neural networks including variants of Tree-LSTM, Tree-based CNN, RNTN, and non-tree models including variants of LSTMs, CNNs, residual, and self-attention based networks", "Sentence classification baselines: RNTN (Socher et al. 2013), AdaMC-RNTN (Dong et al. 2014), TE-RNTN (Qian et al. 2015), TBCNN (Mou et al. 2015), Tree-LSTM (Tai, Socher, and Manning 2015), AdaHT-LSTM-CM (Liu, Qiu, and Huang 2017), DC-TreeLSTM (Liu, Qiu, and Huang 2017), TE-LSTM (Huang, Qian, and Zhu 2017), BiConTree (Teng and Zhang 2017), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), TreeNet (Cheng et al. 2018), CNN (Kim 2014), AdaSent (Zhao, Lu, and Poupart 2015), LSTM-CNN (Zhou et al. 2016), byte-mLSTM (Radford, Jozefowicz, and Sutskever 2017), BCN + Char + CoVe (McCann et al. 2017), BCN + Char + ELMo (Peters et al. 2018). \nStanford Natural Language Inference baselines: Latent Syntax Tree-LSTM (Yogatama et al. 2017), Tree-based CNN (Mou et al. 2016), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), NSE (Munkhdalai and Yu 2017), Reinforced Self- Attention Network (Shen et al. 2018), Residual stacked encoders: (Nie and Bansal 2017), BiLSTM with generalized pooling (Chen, Ling, and Zhu 2018)."], "all_classes": null}
{"length": 4527, "pred": " question. question is a single question as single. question. question. question. question the question is a single. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null}
{"length": 2655, "pred": " a question as single question as single question. If possible the question the question is the article is yes, yes, answer. If the question, answer is yes, answer \"answer\", \"answer\". yes\", Do: not provide the question. Introduction we are the question. We are a question as single question as single question the question. If the answer, yes, answer, yes, answer\", not. Do: question.", "answers": ["name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)"], "all_classes": null}
{"length": 2204, "pred": " the data.", "answers": ["spot patterns by just looking at a collection of images, tag all descriptions with part-of-speech information, I applied Louvain clustering", "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging"], "all_classes": null}
{"length": 2285, "pred": " Winograd, 2, 201, 201, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 17, 25, 26, 42, 44, 57, 60, 71, 78, 79, 86, 97, 98, 111, 114, 127, 144, 132, 144, 145, 156, 156, 187, 187, 234, 234, 256, 345", "answers": ["English, French, German ", "French, English, Spanish, Italian, Portuguese, Hebrew, Arabic"], "all_classes": null}
{"length": 3210, "pred": " the question as sentence as single phrase.", "answers": ["Stacked LSTMs, Cell-aware Stacked LSTMs, Sentence Encoders, Top-layer Classifiers"], "all_classes": null}
{"length": 6169, "pred": " BIB, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF, BREF", "answers": ["Yes", "Unanswerable"], "all_classes": null}
{"length": 3045, "pred": " the process is crucial of the organization's performance. The organization's process to evaluate the employee's and the day and process is a day. The day and day. The day's. The day's process is a day is a day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day. The day", "answers": ["LSA, TextRank, LexRank and ILP-based summary.", "LSA, TextRank, LexRank"], "all_classes": null}
{"length": 3725, "pred": " the question is a question.", "answers": ["hLSTM", "hLSTM"], "all_classes": null}
{"length": 4180, "pred": " passing BREF, BREFs are the neural networks BREFs. BREFs have been investigated. However, B, BNNs closely. Some examples of. These are passing. Some include BREFs BREFs are with the same. These are spectralREFs. BREFs. BREFs. BREFs are spectral. spectral. spectralREFs. BREFs. BREFs are spectral. spectralREFs. spectralREFs. spectralREFs.REFs.REFs. spectralREFs. spectralREFs.REFs.REFs.REFsREFsREFsREFs", "answers": ["Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets."], "all_classes": null}
{"length": 1908, "pred": " the question as single sentence as using sentence. If based on the question the article the article is yes, \"answer is yes\", \"answer\", \"answer\", \"answer\", not explanation. If the question. What is yes, not.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null}
{"length": 2453, "pred": " classification task. We are a classification using a question as single sentence as single sentence. The question. The question. The question is a question is a question. The question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "all_classes": null}
{"length": 2492, "pred": " in various datasets, and datasets in recent BIB, BIB, BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF", "answers": ["Table TABREF6, Table TABREF8", "when testing on English, the F1 score of the model training on Chinese (Zh) is 53.8,  F1 score is only 44.1 for the model training on Zh-En"], "all_classes": null}
{"length": 5151, "pred": " we can be the dialogue with this dialogue.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null}
{"length": 3796, "pred": " the samples to the distribution. We are generated by the discriminator and generator. This is the discriminator. This is the discriminator.", "answers": ["ARAM has achieved improvement over all baseline methods using reverese perplexity and  slef-BLEU metric.  The maximum reverse perplexity improvement 936,16 is gained for EMNLP2017  WMT  dataset and  48,44 for COCO dataset.", "Compared to the baselines, ARAML does not do better in terms of perplexity on COCO and EMNLP 2017 WMT datasets, but it does by up to 0.27 Self-BLEU points on COCO and 0.35 Self-BLEU on EMNLP 2017 WMT. In terms of Grammaticality and Relevance, it scores better than the baselines on up to 75.5% and 73% of the cases respectively."], "all_classes": null}
{"length": 4119, "pred": " the hate, the question as a question is a question as single phrase. If the question, or answerable question, \"answer is \"yes\", \"answer\", \"answer\", \"answer\". Do people on the question. If the question is a question, \"answerable question, \"answer\", \"answer\", \"answer\", Do people can be the question, \"answer the question, \"answer\", \"answer\", Do people can be the question, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null}
{"length": 3855, "pred": " what is a question.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null}
{"length": 2843, "pred": " a question as single sentence as single sentence. If the question the question is the answer is yes, \"answerable question\", \"answer\", \"answer\", \"answer\", \"un\". Yes, not provide Introduction NER question. Entity Recognition a question is a sentence as single sentence is a sentence the question the answerable question, \"answer\", \"answer\", \"answer\", \"answer\", not provide the question. Yes. Introduction is a question is a sentence the answerable question as single sentence the answer\", \"answer\", \"answer\", not. Yes.", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "all_classes": null}
{"length": 3566, "pred": " the task.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null}
{"length": 1971, "pred": " the question as single question as using the question. If based on the question the question the question is the question. If the question. The question is a question is a question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question.", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "all_classes": null}
{"length": 2379, "pred": " a question as a question as single sentence if possible the question. The answer is not the question, if the question, answer is yes, answer, \"answer \"answer\", \"answer\", \"do\". Do: not provide the question. Introduction speech is a question as a question. The question as single sentence. If the question, answer, answer, answer, \"answer \"answer\", \"do\". Do: question, not provide the question. Introduction speech is a question. question,answer as single question, \"answer\", \"answer\", Do question, not provide the question, not provide a question, answer. question,answer \"", "answers": ["7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)", "KARA ONE BIBREF17 , composed of multimodal data for stimulus-based, imagined and articulated speech state corresponding to 7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)"], "all_classes": null}
{"length": 4085, "pred": " the headline of the headline is a headline. The headline. The headline is a headline is a headline. Headline of the headline. Headline. Headline is a headline. Headline is a headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline. Headline", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "all_classes": null}
{"length": 2074, "pred": " the question as a question as using the question as single phrase. If the question the question the question the question the question is the question is the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question the question", "answers": ["Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT),  Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN)", "Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT), CNN, RNN"], "all_classes": null}
{"length": 1914, "pred": " to be a question as single phrase. The question. The question is single sentence is single the question the question the question the question the question the question is yes, answer is yes, \"answer \"answer\", \"answer\", \" Do: not provide Introduction of language. What is the question. The question is the question the question the question the question is the question, the question, the question is \"answer\", \"answer\", \" Do the question the question the question the question the question the question is \"answer\", \"answer\", \"answer the question the question the question the question the question the question isanswer the question the question the", "answers": ["uni-directional model to augment the decoder", "bi-directional language model to augment the sequence to sequence encoder ,  uni-directional model to augment the decoder"], "all_classes": null}
{"length": 3640, "pred": " the dataset for tasks.", "answers": ["One can think $(1-p_{i1})$ as a weight associated with each example, which changes as training proceeds. The intuition of changing $p_{i1}$ to $(1-p_{i1}) p_{i1}$ is to push down the weight of easy examples. For easy examples whose probability are approaching 0 or 1, $(1-p_{i1}) p_{i1}$ makes the model attach significantly less focus to them. Figure FIGREF23 gives gives an explanation from the perspective in derivative: the derivative of $\\frac{(1-p)p}{1+(1-p)p}$ with respect to $p$ approaches 0 immediately after $p$ approaches 0, which means the model attends less to examples once they are correctly classified.", "associates each training example with a weight in proportion to $(1-p)$, and this weight dynamically changes as training proceeds"], "all_classes": null}
{"length": 2443, "pred": " can be the most likely to be the same as a question is the question.", "answers": ["Reward of 11.8 for the A2C-chained model, 41.8 for the KG-A2C-chained model, 40 for A2C-Explore and 44 for KG-A2C-Explore.", "KG-A2C-chained and KG-A2C-Explore both pass the bottleneck of a score of 40"], "all_classes": null}
{"length": 3701, "pred": " the model the model.", "answers": ["Bayesian model of garg2012unsupervised as our base monolingual model"], "all_classes": null}
{"length": 3018, "pred": " the question as a question as single question, if possible the question the question the answer is not answerable question. If the answer, \"yes\", \"answer is \"answer\", \"answer\", \"answer\". Question as possible.", "answers": ["Unanswerable", "Original transcription was labeled with additional labels in [] brackets with nonstandard pronunciation."], "all_classes": null}
{"length": 4186, "pred": " the question as single sentence as using sentence. If based on the question the question the article is the article isanswerable question, If yes \"yes\", \"answer\", \"answer\", \"answer\", Do: not provide the question. Introduction of these techniques on deep learning models to these models shifts the models the perturb models. Evenceptible models the attacks are robust models the attacks, which counterexamples in adversarial research, adversarial research, misspellings are adversarial. spamming the adversarial, to spamming, to detect the BIB, which are adversarial spamming B. As the B, adversarial advers", "answers": ["A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal characters", "processes a sentence of words with misspelled characters, predicting the correct words at each step"], "all_classes": null}
{"length": 2697, "pred": " now a question as single question as single phrase. If possible the question the question the answer is not information. The question. The question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question.", "answers": ["Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish and Swedish", "Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish , Swedish"], "all_classes": null}
{"length": 4113, "pred": " 4, and the model is a question as well as a question, if the question is the question. The answerable, and the question is a question is \"answerable question, \"answer\", \"answer\", \"answer\", \"answer\", \"answer\". Do: \"answerable explanation is a question. This is a question is a question. The question, the question, the question is the question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question, question", "answers": ["NCEL consistently outperforms various baselines with a favorable generalization ability"], "all_classes": null}
{"length": 4592, "pred": " International Workshop on Intelligence of Health ofIAI Conference on Artificial Intelligence burn to physicians are a question as the world's experience of the world BREF, BREF physicians. Physicians and B for direct patients spent clinical hours Electronic Records. As General Organization (MP and Massachusetts BREF by average tasks on administrative tasks of 23.7.2 in 27.9.7 the spent 2017, found to be administrative burden on administrative tasks of working, and medication, and reconciliations, and other information between the reasons. We are exchanged with doctors. Involving data and clinical data. BREF, and clinical BREF", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 2132, "pred": " can be a question as single sentence. If the question.", "answers": ["error detection system by Rei2016", "error detection system by Rei2016"], "all_classes": null}
{"length": 3432, "pred": " search for online databases, such as online diagnosis. The user, search that outputs that outputs the clinical entities. The user describes that outputs the outputs. For example, the user entities. For example, the user query that outputs the query and search. For example, the user outputs that outputs the outputs the outputs. For example, the example, the outputs, the outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs, outputs", "answers": ["clinical notes from the CE task in 2010 i2b2/VA", "clinical notes from the CE task in 2010 i2b2/VA "], "all_classes": null}
{"length": 3919, "pred": " the model is a question as well as the question, and the question, and the question is the question. We are the question is a question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question", "answers": ["ecause this process is similar to the cloze task in BERT's pre-train process, therefore by using the ability of the contextual language model the decoder can generate more fluent and natural sequences."], "all_classes": null}
{"length": 1902, "pred": " the platform with semantic applications. BREF and representation as BIB, paraphrase BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF BREF", "answers": ["Unanswerable", " Paraphrase Database (PPDB) ,  book corpus", "Unanswerable"], "all_classes": null}
{"length": 2108, "pred": " the world 80, 2017 cancer diagnosis a question as single cancer diagnosis report. The cancer diagnosis. This is a report and pathology and pathology. The report and histopathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology. The pathology.", "answers": ["Unanswerable"], "all_classes": null}
{"length": 1947, "pred": " there a question as a question as using a question as single sentence. If possible the question the question the question the question is not information. If based the answerable question \"yes\", \"answer is \"answer\", \"answer\", \"answer\", Do: not provide. If not. Introduction there is a question. How to be a question as single sentence the question the question the question the question. If the answer is notanswerable question \"answer\", \"answer\", not. If the question. If the question the question the question is notanswerable question. If the answerable question.", "answers": ["no evidence of depression, depressed mood, disturbed sleep, fatigue or loss of energy", "The annotations are based on evidence of depression and further annotated by the depressive symptom if there is evidence of depression"], "all_classes": null}
{"length": 2800, "pred": " the question as a question as single the question is yes, if based on the question.", "answers": ["BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800", "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800"], "all_classes": null}
{"length": 2423, "pred": " in the message is a question as using the question. If you scientific the question. The question is, the question. If not, answer is yes, answer. \"answer \"yes\", \"answer\", \"answer\", do: not provide the explanation the question. If the question. In the question is. If you are question. question. question. question. If you, the question, the question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question.", "answers": ["using the machine translation platform Apertium ", "machine translation platform Apertium BIBREF5"], "all_classes": null}
{"length": 4177, "pred": " the scientific question as single sentence as possible question. If based on the question the answerable, If the question is \"answer is \"yes\", \"answer\", \"answer\", \"answer\". yes\", not provide the question. If the question. Introduction the question is a sentence as single sentence. If the question. If the answerable question is \"answerable question, \"answer\", \"answer\", not\". yes\", not provide the question. If the question. Question the answer is yes, not the question. If the answerable question. Questionable sentence. If the answerable question, not the question, not the answerable question", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null}
{"length": 3001, "pred": " the purpose of the audience, and the Internet, the mechanism of the social media, the propaganda very large BIB, BIB, BREF techniques as a specific.", "answers": ["The baseline system for the SLC task is a very simple logistic regression classifier with default parameters. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly.", "SLC task is a very simple logistic regression classifier, FLC task generates spans and selects one of the 18 techniques randomly"], "all_classes": null}
{"length": 2991, "pred": " a question as single sentence. If the question is a sentence. The question is a question. The question is a question is a question. The question. The question is a question. The question is a question. The question. The question. The question is a question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "all_classes": null}
{"length": 4882, "pred": " we are a question as single article as single question, if the question.", "answers": ["By assigning a political bias label to each news article and training only on left-biased or right-biased outlets of both disinformation and mainstream domains", "we also account for political biases inherent to different news sources, referring to the procedure proposed in BIBREF2 to label different outlets. Overall we show that we are able to classify credible vs non-credible diffusion networks (and consequently news articles) with high accuracy (AUROC up to 94%), even when accounting for the political bias of sources (and training only on left-biased or right-biased articles). We observe that the layer of mentions alone conveys useful information for the classification, denoting a different usage of this functionality when sharing news belonging to the two news domains. We also show that most discriminative features, which are relative to the breadth and depth of largest cascades in different layers, are the same across the two countries."], "all_classes": null}
{"length": 3722, "pred": " Chinese is a question as a question as single sentence. If possible the question the question is not answerable, if answered the question \"yes\", \"answer\", \"answer\", \"answer\", \"answer\". yes\", \"not\". Introduction the question is Chinese is a question. Chinese is a sentence. Chinese and Chinese culture of the culture and culture and Chinese culture of ancient Chinese people's culture. Chinese understand, and culture, and culture is difficult to develop it modern Chinese. Chinese is Chinese, modern. Chinese and concise is Chinese and modern is modern while Chinese are ancient. Chinese are most words are ancient words are ancient words are most.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null}
{"length": 2240, "pred": " a question as a question as single sentence as possible. If the question the question the question is the answer is yes, \"answerable question\", \"answer\", \"answer\", \"answer\". yes\", Do: not explanation has been a question.", "answers": ["English", "English ", "English"], "all_classes": null}
{"length": 2545, "pred": " the question as using the question as single sentence.", "answers": ["Answer with content missing: (Data section) Chinese with version 5.1 of the Chinese Penn Treebank (CTB)"], "all_classes": null}
{"length": 4487, "pred": " Creative Commons Attribution 4 License http://creativecommons.org/licenses/by neural networks BIB BREF BREF BREF B networks ( BREF networks or social media, neural networks BREF networks BREF networks BREF on Twitter is a social media, and social media, and the user, user, user, the post, the post, comment, comment, and the post, and the user's post, user, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post, post", "answers": ["eight layers"], "all_classes": null}
{"length": 4661, "pred": " the question as single sentence as possible the question. If not the question the question is answerable, \"yes\", \"answer\", \"answer\", \"answer\". Do Introduction photo. What is a question as question. What is the question the question. What is the question, \"answer\", \"answer\", \"answer\", Do question. What is the question the question the question. What is the question, answer is the question, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer,", "answers": [" the same datasets as BIBREF7", "same datasets as BIBREF7"], "all_classes": null}
{"length": 4528, "pred": " this century of data. This century has become pervasive data processing is a blessing and data and benefits for data the data science of data science the data science. This data science. This data has a data science and data science, but data, but data, but data, but data science data science data science and data, data, data, data, data, data, data science data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data, data,", "answers": ["MEDDOCAN, NUBes-PHI", "MEDDOCAN, NUBes "], "all_classes": null}
{"length": 3543, "pred": " a question as a question, if the question is not. The question is yes, yes, answer, answer, \"answer is \"un\". yes\", Do: \"answer\". Introduction is a question, not. What is a question, \"answer is yes, \"answer\", \"answer\". Do: is, not. Question is yes, answer, answer, \"answer is, \"answer\", \"answer\", not, Do: is, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer", "answers": ["Unanswerable"], "all_classes": null}
{"length": 5869, "pred": " the problem. We are not inference as a question as a query, and the user. We can be the answer is a question. We can be the answer. We can be the answer the question as a question is a question. We can be the answer. We can be the question. We can be the answer. We can be the question. We can be the answer. We can be the question. We can be the answer. We can be the question. We can be the answer. We can be the question. We can be the answer. We can be the question. We can be the answer. We can be", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null}
{"length": 1910, "pred": " the question.", "answers": ["Yes", "No"], "all_classes": null}
{"length": 2234, "pred": " stance is a question as single sentence as single. If possible the question the question the question the article is not answer, If the answerable question, the question \"yes \"answer\", \"answer\", \"answer\", \" Do: \" Do: Which explanation detection is a question. Which stance is sentence the question the answerable question. Which question the answer, \"answer\", \"answer\", \" Do: Which question the question the answerable question the question, \"answer\", \"answer\", \"answer\", \" Do question the question the question the answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer", "answers": ["Galatasaray, Fenerbahçe", "Galatasaray , Fenerbahçe "], "all_classes": null}
{"length": 4600, "pred": " the irony, which is widely used as a meaning B defined as a sentence. As a meaning B aspect of B plays an essential role, opinion, plays BREF, BREF some attention to irony BREF on B4 focus, BREF studies little attention to irony. Sentimentalize, we strengthen the generation. As a network to sentence to the sentiment is stronger. The input and the same polarity is the example is when it ruined as my \"plans to be negative, and like. We use. He or she is sentiment. The polarity as my polarity is to preserve. Can be ironic. Can be. Which is mentioned", "answers": ["Irony Classifier, Sentiment Classifier for Irony, Sentiment Classifier for Non-irony, transformation from ironic sentences to non-ironic sentences"], "all_classes": null}
{"length": 3612, "pred": " the information.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null}
{"length": 4005, "pred": " a question, as single sentence as single question, if the question the question is possible the answer is yes, or answer. \"answer\", \"answer\", \"answer\". yes\", Do Introduction of explanations in the questionings are social, and psychological. For example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example, example", "answers": ["Facebook status update messages", "Facebook status update messages"], "all_classes": null}
{"length": 4855, "pred": " a sentence as, a question or sarcastic, or sarcastic. If not the sentiment. The features. We are the features of the dataset is a question, and the question, the question, the question. If not the answer is a yes, \"yes\", \"answer\", \"answer\", \"un\". Do: the question, not explanation is. What is a sentence. As a question, we, we are the question, the question, the question, the question, the answer is the question, the question, the question, the question, the question, the question, the question, the question, the question, the", "answers": [" The features extracted from CNN."], "all_classes": null}
{"length": 2753, "pred": " the features of the features or features of the features. Although domain. Although such as well as simple methods are useful, such systems across datasets are B that are B that are B, yet powerful across. However perform that the spaces are in embeddings that is an embeddings that space. Such as the vector are text features as the performance. Such as the model, B, B, deep learning. However in spaces to be linearize the vectorREF in. B3 high-dimensional the reason of the performance in the space like the tasks like the model, using embeddings. Using the work, expressiveness of this approach a text, that we explore", "answers": ["number of clusters, seed value in clustering, selection of word vectors, window size and dimension of embedding", "different number of clusters, different embeddings"], "all_classes": null}
{"length": 2424, "pred": " in the question as using the question. is single sentence. If not, If based the question the question is yes, answer. \"yes\", \"answer\", \"answer\", do: \"answer\", do: the question. If the question is yes, answer. yes, \"answer\", \"answer\", do. If the question, answer. Yes, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer, answer", "answers": ["column Ens Test in Table TABREF19"], "all_classes": null}
{"length": 2669, "pred": " medical plays an important role in the development. To the area of Natural Language that is dedicated Processing that medically relevant data. Only annotated is high category. One medical the domain and diseases and corpora the most of them and chemicals the BIB, BIB, BREF corpus the corpus BDE or disease. Disease annotations of annotations of new annotations. annotations of annotated. We are made in the case. The disease, a case, and diseases, focus on pulmonary 10 presented. A focusing 143 a corpus 143 a finding the corpus. focusing on case. Their case is the case is clinical. We annotate. We annotate the", "answers": ["8,275 sentences and 167,739 words in total", "The corpus comprises 8,275 sentences and 167,739 words in total."], "all_classes": null}
{"length": 2764, "pred": " we can be a question as single question. If the question is a question.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null}
{"length": 3591, "pred": " the problem, such as basketball, and sports words like polarity and sentiment.", "answers": ["text classification for themes including sentiment, web-page, science, medical and healthcare"], "all_classes": null}
{"length": 5838, "pred": " the question.", "answers": ["bag-of-words model, CNN"], "all_classes": null}
{"length": 3294, "pred": " the same as the best, and the most of the model.", "answers": ["By 14 times.", "up to 1.95 times larger"], "all_classes": null}
{"length": 2835, "pred": " \"ORG, and the dataset.", "answers": ["3606", "6946"], "all_classes": null}
{"length": 2474, "pred": " the classification, and the data, and the data, and the data. The data is a question as the question as the question is yes, answer, answer, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question, the question", "answers": ["MLP", "Eusboost, MWMOTE"], "all_classes": null}
{"length": 3784, "pred": " the model the word embeddings, and the model.", "answers": ["Yes", "Yes"], "all_classes": null}
{"length": 4320, "pred": " a question as single question as possible the question is possible the question. If based on the answerable, \"yes\", \"answer is \"answer\", \"answer\". Do: \"not\". Do Introduction a question is a question as possible the question. Inference for example of a question. If the question is possible, \"answerable question. \"answer\", \" Do question. Do question. If the question is possible, answerable question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["Yes", "Unanswerable"], "all_classes": null}
{"length": 6810, "pred": " the question is a question. As question we are question.", "answers": ["0.5115", "0.6103"], "all_classes": null}
{"length": 4327, "pred": " a question as single question as single sentence is possible the question. If based the question the answerable, If not information is \"answer is \"yes\", \"answer\", \"answer\", Do: \"un\". Question is not provide a question. Data for example the question. As single sentence the question the answerable is the question. If not, \"answerable question \"answer\", \" Do: \"answer\", not provide a question. Question the question the answerable is \"answerable question.", "answers": [" Wall Street Journal (WSJ) portion of the Penn Treebank", "Unanswerable"], "all_classes": null}
{"length": 1692, "pred": " the most of the framework is a question, and the framework.", "answers": ["By conducting a survey among engineers", "Unanswerable"], "all_classes": null}
{"length": 4524, "pred": " question. question is a single question as single. question. question. the question. question. question is single. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question. question", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null}
