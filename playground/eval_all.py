import torch
import re
import time
from datasets import load_dataset, get_dataset_config_names
from transformers import AutoTokenizer, AutoModelForCausalLM
import os 
import json
# --- é…ç½® ---
# âš ï¸ æ›¿æ¢æˆä½ çš„æ¨¡å‹è·¯å¾„ï¼
model_path = "/root/playground/Qwen2-1.5B-Instruct" 
# ----------------

device = "cuda" if torch.cuda.is_available() else "cpu"

# 1. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ (åªéœ€åŠ è½½ä¸€æ¬¡)
print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype="auto",
    device_map="auto"
)
model.eval()

# 2. è‡ªåŠ¨è·å–C-Evalæ‰€æœ‰å¯ç”¨çš„ç§‘ç›®åç§°
try:
    all_subjects = get_dataset_config_names("ceval/ceval-exam")
    print(f"æˆåŠŸè·å–C-Evalæ‰€æœ‰ç§‘ç›®ï¼Œå…± {len(all_subjects)} ä¸ªã€‚")
except Exception as e:
    print(f"è‡ªåŠ¨è·å–ç§‘ç›®å¤±è´¥: {e}")
    # å¦‚æœè‡ªåŠ¨è·å–å¤±è´¥ï¼Œä½¿ç”¨ä¸Šæ¬¡æŠ¥é”™ä¿¡æ¯ä¸­çš„ç¡¬ç¼–ç åˆ—è¡¨ä½œä¸ºå¤‡ç”¨
    all_subjects = ['accountant', 'advanced_mathematics', 'art_studies', 'basic_medicine', 'business_administration', 'chinese_language_and_literature', 'civil_servant', 'clinical_medicine', 'college_chemistry', 'college_economics', 'college_physics', 'college_programming', 'computer_architecture', 'computer_network', 'discrete_mathematics', 'education_science', 'electrical_engineer', 'environmental_impact_assessment_engineer', 'fire_engineer', 'high_school_biology', 'high_school_chemistry', 'high_school_chinese', 'high_school_geography', 'high_school_history', 'high_school_mathematics', 'high_school_physics', 'high_school_politics', 'ideological_and_moral_cultivation', 'law', 'legal_professional', 'logic', 'mao_zedong_thought', 'marxism', 'metrology_engineer', 'middle_school_biology', 'middle_school_chemistry', 'middle_school_geography', 'middle_school_history', 'middle_school_mathematics', 'middle_school_physics', 'middle_school_politics', 'modern_chinese_history', 'operating_system', 'physician', 'plant_protection', 'probability_and_statistics', 'professional_tour_guide', 'sports_science', 'tax_accountant', 'teacher_qualification', 'urban_and_rural_planner', 'veterinary_medicine']

# ç”¨äºå­˜å‚¨æ‰€æœ‰ç§‘ç›®ç»“æœçš„å­—å…¸
results = {}

# 3. å¾ªç¯æµ‹è¯•æ¯ä¸€ä¸ªç§‘ç›®
total_start_time = time.time()
for subject_name in all_subjects:
    print(f"\n--- å¼€å§‹è¯„æµ‹ç§‘ç›®: {subject_name} ---")
    subject_start_time = time.time()
    
    dataset = load_dataset("ceval/ceval-exam", name=subject_name, split="dev")
    
    correct_count = 0
    total_count = len(dataset)
    
    for i, sample in enumerate(dataset):
        question = sample['question']
        choices = f"A. {sample['A']}\nB. {sample['B']}\nC. {sample['C']}\nD. {sample['D']}"
        prompt = f"ä»¥ä¸‹æ˜¯ä¸­å›½å…³äºâ€œ{subject_name}â€çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ç›´æ¥ç»™å‡ºæ­£ç¡®é€‰é¡¹çš„å­—æ¯ã€‚\n\né¢˜ç›®ï¼š{question}\n{choices}\nç­”æ¡ˆï¼š"
        
        messages = [{"role": "user", "content": prompt}]
        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        
        model_inputs = tokenizer([text], return_tensors="pt").to(device)
        
        generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=5)
        generated_ids = [
            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        response_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        print("é¢˜ç›®æè¿°ï¼š", prompt)
        print("æ¨¡å‹å›ç­”ï¼š",response_text)
        match = re.search(r'([A-D])', response_text)
        model_answer = match.group(1) if match else None
        
        if model_answer == sample['answer']:
            correct_count += 1
            
    accuracy = correct_count / total_count if total_count > 0 else 0
    results[subject_name] = accuracy
    
    subject_end_time = time.time()
    print(f"âœ… ç§‘ç›® '{subject_name}' è¯„æµ‹å®Œæˆã€‚å‡†ç¡®ç‡: {accuracy:.2%}, è€—æ—¶: {subject_end_time - subject_start_time:.2f} ç§’")

# 4. æ±‡æ€»å¹¶æ‰“å°æœ€ç»ˆç»“æœ
print("\n\n--- æ‰€æœ‰ç§‘ç›®è¯„æµ‹å®Œæˆ ---")
print(f"æ¨¡å‹: {model_path}")
print("-" * 50)
print(f"{'ç§‘ç›®':<40} | {'å‡†ç¡®ç‡':<10}")
print("-" * 50)
for subject, acc in results.items():
    print(f"{subject:<40} | {acc:<10.2%}")
print("-" * 50)

average_accuracy = sum(results.values()) / len(results) if results else 0
total_end_time = time.time()

print(f"ğŸ“Š **å¹³å‡å‡†ç¡®ç‡ (Average Accuracy): {average_accuracy:.2%}**")
print(f"â±ï¸ **æ€»è€—æ—¶: {(total_end_time - total_start_time) / 60:.2f} åˆ†é’Ÿ**")

# åˆ›å»ºç»“æœç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
results_dir = "results"
os.makedirs(results_dir, exist_ok=True)

# å‡†å¤‡ä¿å­˜çš„ç»“æœæ•°æ®
result_data = {
    "model_path": model_path,
    "average_accuracy": average_accuracy,
    "total_time_minutes": (total_end_time - total_start_time) / 60,
    "subject_results": results,
    "timestamp": time.strftime("%Y-%m-%d_%H-%M-%S")
}

# ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ¨¡å‹åç§°å’Œæ—¶é—´æˆ³ï¼‰
model_name = os.path.basename(model_path.rstrip("/"))
filename = f"{results_dir}/{model_name}_ceval_results_{time.strftime('%Y%m%d_%H%M%S')}.json"

# ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
with open(filename, "w", encoding="utf-8") as f:
    json.dump(result_data, f, ensure_ascii=False, indent=4)

print(f"\nâœ… è¯„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {filename}")